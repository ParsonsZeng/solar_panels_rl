\documentclass[11pt]{article}

% --- Packages ---
\usepackage{rldm}
%\usepackage[usenames, dvipsnames]{color} % Cool colors
\usepackage{enumerate, amsmath, hyperref, amsthm, verbatim, amssymb, dashrule, tikz, bbm, booktabs, bm}
\usepackage[framemethod=TikZ]{mdframed}
\usepackage[numbers]{natbib}



% --- Misc. ---
\hbadness=10000 % No "underfull hbox" messages.

% --- Commands ---
\input{commands}

% --- Meta Info ---
\title{Improving Solar Panels with Reinforcement Learning}


\author{
Emily Reif \\
Department of Computer Science\\
Brown University\\
Providence, RI 02912 \\
\texttt{emily\_reif@brown.edu} \\
\And
David Abel \\
Department of Computer Science\\
Brown University \\
Providence, RI 02912 \\
\texttt{david\_abel@brown.edu} \\
}

%\author{Emily Reif  and David Abel \\ \texttt{\{emily\_reif@brown.edu, david\_abel@brown.edu\}} \\ Department of Computer Science, Brown University, Providence, RI 02912 }
\date{}

% --- Begin Document ---
\begin{document}
\maketitle

% -----------------
% -- Abstract --
% -----------------
\begin{abstract}
Solar panels sustainably harvest energy from the sun. To improve performance, solar panels are often equipped with a tracking mechanism to compute the sun's relative location in the sky throughout the day. Based on the tracker's estimate of the sun's location, a controller rotates the panel along one or two axes to minimize angle of incidence between solar irradiance and the grid of photovoltaic cells, increasing total energy harvested. Prior work has developed tracking algorithms for computing the sun's location based on the longitude and latitude of the system, the current temperature, time of day, altitude, local atmospheric pressure, among other quantities.
%
However, these approaches do not account for diffuse irradiation in the sky, reflected irradiation on the ground and surrounding surfaces, weather conditions (such as cloud coverage), or atmospheric composition, all of which can be contributing factors to the total energy harvested by a solar panel.
%
In this work, we apply the computational learning paradigm of Reinforcement Learning to optimize solar tracking and increase the total amount of AC energy harvested by solar panels. We advocate for the use of Reinforcement Learning to solve the solar tracking problem due to its {\it effectiveness}, {\it negligible cost}, {\it lack of dependence on extra components} (such as a thermometer, barometer, or a GPS), and {\it versatility}. Our contribution is twofold: (1) the adaptation of state of the art RL algorithms to improving solar panels, and (2) the creation of an open source simulation platform for solar tracking experimentation. We evaluate the utility of our algorithm compared to the standard state of the art tracking algorithms, a random tracker, a fixed tracker, and a less sophisticated RL algorithm in our simulated environment across different time scales, in different places on Earth, and using dramatically different percepts (sun coordinates and synthetic images of the sky).
\end{abstract}

% ----------------------
% -- Introduction --
% ----------------------
\section{Introduction}
Solar energy offer a pollution free and sustainable means of harvesting energy directly from the sun. Considerable effort has been directed toward maximizing the efficiency of end to end solar systems, including the design of photovoltaic cells, the layout of panels, engineering new photovoltaic architectures and materials, and solar tracking systems\dnote{I'd like citations here}. Solar tracking is especially important for maximizing performance of solar panels~\cite{Eke2012,Rizk2008,King2001}. Given the proper hardware, a tracking algorithm computes the relative location of the sun in the sky throughout the day and a controller moves the panel along one or two axes to point at the sun. The goal is to minimize the angle of incidence between incoming solar irradiance and the grid of photovoltaic cells, as in~\citet{Eke2012,Benghanem2011,King2001, kalogirou1996design}. Prior work has consistently demonstrated that panels using a tracking system increase the total energy by a substantial amount:~\citet{Eke2012} report that a dual-axis tracker yielded 71 kW/h, compared to a fixed panel's yield of 52 kW/h on the same day. Eke and Senturk also report energy harvesting gains of dual-axis tracking systems over fixed systems varying from 15\% to 40\%, depending on the time of year. Clearly, tracking can dramatically benefit solar photovoltaic systems.

Existing solar tracking algorithms are sufficiently accurate to inform control of panels.~\citet{reda2004solar} develop an algorithm that computes the location the two panel-relative angles needed to determine the sun's location in the sky within $\pm 0.0003$ degrees of accuracy. Further, the algorithm is advertised as accurate between the years 2000 B.C.E to 6000 A.D, making it robust to the movements of relevant celestial bodies for the foreseeable future.

There are three limitations to this solar tracking algorithm. First, it's computationally inefficient to the point of impracticality. Second, the algorithm requires a variety of data not easily available, especially in locations commonly home to large grids of solar panels. Third, prior work suggests that pointing a panel directly at the sun is not always optimal behavior~\citet{Kelly2009,Hussein1995,King2001}; the total solar irradiation hitting a panel is a combination of {\it direct}, {\it reflective}, and {\it diffuse} irradiation~\cite{Benghanem2011}. Thus, under certain conditions, optimal performance may involve prioritizing reflective or diffuse irradiation, when direct sunlight is not available (due to clouds or other obfuscations). Consequently, pointing panels directly at the sun may  occasionally achieve sub-optimal behavior. Other algorithms have addressed the first two limitations, focusing on creating a computationally efficient solar tracking algorithm that depends on a small number of easily accessible input data. The most widespread of these approaches is introduced by~\citet{Grena2008}, achieving computational efficiency but still depending on data like longitude, latitude, atmospheric pressure, and the temperature. \\ 

In this work, we advocate for the use the computational paradigm of Reinforcement Learning (RL) to optimize solar panel performance. We advocate for the use of RL due to its {\it effectiveness}, {\it negligible cost}, {\it lack of dependence on extra components} (such as a GPS), and {\it versatility}. That is, using RL, solar tracking and control can take into account other environmental factors like temperature, cloud coverage, and atmospheric conditions, offering an efficient yet adaptive solution that can optimize for the given availability of each type of solar irradiation. We adapt state of the art RL approach of Deep $Q$-Networks to optimize solar energy harvesting, create a simulation platform for solar energy harvesting, and test the utility of our algorithm in this simulated environment against various baselines.

We are in the process of building a physical system for the purpose of conducting experiments outside of simulation -- to this end, our simulation includes multiple perceptual modes of information. In the simplest case, the percepts given to the RL algorithm are the angles of the sun and the panel (that is, there are four state variables). In the more complex case, we use the sun's relative location to synthesize black and white images of the sun's movement throughout the day. The controller is then only given the raw bitmap to make its inference. %Lastly, we simulate cloud coverage by randomly generating small Gaussian blobs in the synthesized images, which affect the solar irradiation that reach the planet's surface.


% ----------------------
% -- Background --
% ----------------------
\section{Background}

% Solar Tracking
\subsection{Solar Tracking}

\img{figures/placeholder.png}{0.2}
\dnote{3D Diagram of sun, label relevant angles}

\dnote{Definitions of all the angles/solar terms, etc.}

\subsection{Why Use RL for Solar Tracking?}

\dnote{Not sure we need this paragraph. Might already be explained above.}
There are three primary limitations of existing solar tracking algorithms: (1) Computational Inefficiency, (2) Dependence on unavailable data, (3) Limited optimality. A system that can be iteratively improved by an autonomous learning system can overcome all three of these limitations. At first glance, supervised learning ought to suffice to control such a system, but its effectiveness will depend on the data it trains on. We advocate for RL compared to traditional supervised learning techniques due to the implicit {\it data collection} problem facing solar panels. In particular, the exploration problem central to Reinforcement Learning is present in solar tracking; the experience-energy pairs are only available based on the actions that the agent takes. Consequently, the agent does not get data i.i.d., and so traditional machine learning techniques are ill posed for the setting. Furthermore, decisions made at any one time step have long term consequences, requiring a sequential decision making paradigm.

Lastly,~\citet{Hsu2015} deploy $Q$ Learning on solar panels to configure the operating voltage of the end to end system, enabling higher efficiency. Thus, if hardware for a simple RL agent is already known to be useful for solar panels, we suggest that using RL could then provide both benefits: (1) learning optimal tracking for an arbitrary location and time on earth, and (2) control the operating voltage. \\



% -----------------------------
% -- System Overview --
% -----------------------------
\section{System Overview}

\img{figures/placeholder.png}{0.2}
\dnote{Diagram}

\dnote{I think we want to describe the radiation stuff here. Rename this section ``background".}


% ----------------------
% -- Experiments --
% ----------------------
\section{Experiments}

We conduct proof of concept experiments in a simulated environment to demonstrate the basic validity of the approach. Our most immediate next step is to construct a physical system to truly explore the hypothesis that RL is an effective solution to solar tracking. \\

There are three primary stages of our simulation:
\begin{enumerate}
\item For a given latitude, longitude, year, month, day, and time, simulate the relative positions of the sun to the specified location on earth.
\item Given this relative location, compute the amount of {\it direct} solar irradiation from the sun hitting that point on earth.
\item Given the panel's current tilt angle and orientation, simulate the amount of direct irradiation actually hitting the panel's surface.
\end{enumerate}

Approximating the relative position of the sun in the sky for a point and time on Earth (step 1.) is based on a model originally introduced by~\citet{jordan1958chafer}, discussed at length by~\citet{masters2013renewable}, implemented in the library \texttt{pysolar}. Then, for step 2., we use an implementation of the model from~\citet{masters2013renewable} to estimate the amount of radiation hitting any point on Earth for a given time. Prior studies have demonstrated that the {\it total irradiation} hitting a point on earth is the sum three components:
\begin{equation}
r_{total} = r_{direct} + r_{ground} + r_{sky}
\end{equation}
Where $r_{direct}$ is the most dominent component, indicating the direct irradiation, $r_{ground}$ denotes the irradiation reflected onto the panel's surface from the ground, and $r_{sky}$ denotes the diffuse irradiation from the sky. In our simulation, we are only capturing estimates of $r_{direct}$. However, it is worth noting that $r_{ground}$ and $r_{sky}$ are presently components that are completely ignored by existing tracking and control systems; we take these components be to further motivation to use RL to optimize control of these systems, as an RL system could learn to maximize the ground and sky radiation components when appropriate, without being programmed to do so explicitly.

We wrap these three estimates inside of a Markov Decision Process using the open source library \texttt{simple-rl}\footnote{\url{https://github.com/david-abel/simple_rl}}. The MDP is defined as follows:
\begin{itemize}
\item Each state, $s \in \mc{S}$ is given by: $\{ \texttt{sun percept}, \texttt{panel NS angle}, \texttt{panel EW angle} \}$. The sun percept is varied between experiments.
\item Each action, $a \in \mc{A}$ is one of $\{\texttt{tilt N}, \texttt{tilt E}, \texttt{tilt S}, \texttt{tilt W}, \texttt{nothing}\}$
\item The reward function is simply the amount of solar irradiation hitting the panel's tilted surface at the given timestep.
\item The transition function has two components. The first controls the sun percepts according to the models describred above, and the second dictates the panels movement.
\item $\gamma = 0.99$.
\end{itemize}

All of our code for running experiments and reproducing results is freely available\footnote{\url{https://github.com/david-abel/solar_panels_rl}}.

We run three experiments, each with the same baselines. Our baseline algorithms are:
\begin{itemize}
\item \texttt{random}: A randomly behaving agent.
\item \texttt{fixed}: A panel that remains fixed.
\item \texttt{linear}: A $Q$-Learning with a Linear Function Approximator with radial basis functions used for feature kernels.
%\item \texttt{optimal}: A tracker that always minimizes the angle of incidence to the sun.
\item \texttt{grena}: The efficient algorithm implemented by~\citet{Grena2008}.
\item \texttt{dqn}: A Deep $Q$ Network.
\end{itemize}

\subsection{Experiment One: Coordinates}

In the first case, we evaluate the effectiveness of each approach using a percept representation of:
\begin{equation}
\langle \texttt{sun altitude}, \texttt{sun azimuth}, \texttt{panel altitude}, \texttt{panel azimuth} \rangle
\end{equation}

\subsection{Experiment Two: Synthetic Sky Images}

We then evaluate the effectiveness of each approach using a percept representation of a synthetically generated image
\dnote{Example image}

\subsection{Experiment Three: Synthetic Sky Images with Clouds}

\dnote{Example image}



% ---------------------
% -- Conclusion --
% ---------------------
\section{Conclusion}
















% --- Bibliography ---
\bibliographystyle{plainnat}
\bibliography{../solar}

\end{document}