\documentclass[11pt]{article}

% --- Packages ---
\usepackage[usenames, dvipsnames]{color} % Cool colors
\usepackage{enumerate, amsmath, amsthm, amssymb, fullpage, csquotes, dashrule, tikz, bbm, booktabs, bm}
\usepackage[framemethod=TikZ]{mdframed}
\usepackage[numbers]{natbib}

% --- Misc. ---
\hbadness=10000 % No "underfull hbox" messages.
\setlength{\parindent}{0pt} % Removes all indentation.

% --- Commands ---
\input{commands}

% --- Meta Info ---
\title{Improving Solar Panels with Reinforcement Learning}
\author{Emily Reif  \& David Abel \\ \{emily\_reif@brown.edu, david\_abel@brown.edu\} \\ Department of Computer Science, Brown University, Providence, RI 02912 }
\date{}

% --- Begin Document ---
\begin{document}
\maketitle

% -----------------
% -- Abstract --
% -----------------
\begin{abstract}
Solar panels offer a pollution free and fully sustainable means of harvesting energy directly from the sun. One of the primary factors dictating the efficacy of an individual solar panel is its angle of indicidence to incoming solar irradiance; photovoltaic cells pointed directly at the sun harvest substantially more energy than those pointed away from the sun. Consequently, solar panels are often equipped with a tracking system that enables efficient and accurate computation of the sun's relative location throughout the day, regardless of the panel's location on Earth. With this information, solar panels built with some degree of freedom maximize their energy harvest throughout the day by pointing themselves at the sun. Prior work advances efficient algorithms for computing the sun's location based on the longitude and latitude of the system, the current temperature, time of day, altitude, local atmospheric pressure, among other quantities. Furthermore, these approaches do not account for subtle changes in the local climate, current weather conditions, or atmospheric composition which can be contributing factors to the total energy harvest by a solar panel. In this work, we use the computational learning paradigm of Reinforcement Learning to opimize solar panel performance, measured in terms of the total amount of AC energy harvested in a 24 hour cycle by an end to end solar system. We advocate for the use of Reinforcement Learning for the Solar Tracking problem due to its {\it effectiveness}, {\it negligible cost}, {\it lack of dependence on extra components} (such as a thermometer, barometer, or a GPS), and {\it versatility}. Our contribution is twofold: (1) the development of an RL algorithm, \textsc{SolarRL} designed specifically for optimizing the total energy harvest by solar panels, the creation of an open source simulation platform for solar tracking experimentation. We evaluate the utility of our algorithm compared to baselines in our simulated environment as well as on a fleet of real solar panels, tested during the Fall and Winter in Rhode Island.
\end{abstract}

% ----------------------
% -- Introduction --
% ----------------------
\section{Introduction}
Solar panels offer a pollution free and fully sustainable means of harvesting energy directly from the sun. Consequently, considerable effort has been directed toward maximizing the efficiency of end to end solar systems, including the design of photovolatic cells, the layout of the panels, and solar tracking systems. Solar tracking has been shown to be especially important for improving performance of solar panels~\cite{Eke2012,Rizk2008,King2001}. Systems equipped with a tracking mechanism are designed with either one or two degrees of freedom; the tracker computes the relative location of the sun in the sky throughout the day, enabling individual panels to minimize the angle of incidence between incoming solar irradiance and the grid of photovoltatic cells, as in ~\citet{Eke2012,Benghanem2011,King2001}. In this work, we leverage the computational paradigm of Reinforcement Learning (RL) to optimize solar panel performance, measured in the total amount of energy harvested in a 24 hour cycle. We advocate for the use of RL due to its {\it effectiveness}, {\it negligible cost}, {\it lack of dependence on extra components} such as a GPS, and {\it versatility}. We justify each of these properties, develop a new RL algorithms, \textsc{SOLARL} designed specifically for harvesting solar energy, create a simulation platform for solar energy harvesting, and test the utility of our algorithm in this simulated environment and on a fleet of real solar panels.



% ----------------------
% -- Background --
% ----------------------
\section{Background}


\subsection{Solar Tracking}

\subsection{Reinforcement Learning}



% -----------------------
% -- Related Work --
% -----------------------
\section{Related Work}




% -----------------------------
% -- System Overview --
% -----------------------------
\section{System Overview}



% ----------------------
% -- Experiments --
% ----------------------
\section{Experiments}


\subsection{Simulation}

\subsection{Physical System}



% ---------------------
% -- Conclusion --
% ---------------------
\section{Conclusion}


















% --- Bibliography ---
\bibliographystyle{plainnat}
\bibliography{solar}

\end{document}